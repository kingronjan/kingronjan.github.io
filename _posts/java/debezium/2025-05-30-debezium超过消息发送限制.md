---
categories:
- java
- debezium
date: 2025-05-30 17:55 +0800
id: ab65ff93-c596-4339-9b97-1e7c0769d76a
layout: post
tags:
- java
- debezium
title: debezium超过消息发送限制
---

### 问题

有时候 debezium 会抛出下面的异常：

```
{
    "connector": {
        "state": "RUNNING",
        "worker_id": "xxx.xxx.xx.xxx:8083"
    },
    "name": "MY_CONNECTOR",
    "tasks": [
        {
            "id": 0,
            "state": "FAILED",
            "trace": "org.apache.kafka.connect.errors.ConnectException: Unrecoverable exception from producer send callback\n\tat org.apache.kafka.connect.runtime.WorkerSourceTask.maybeThrowProducerSendException(WorkerSourceTask.java:266)\n\tat org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:320)\n\tat org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:248)\n\tat org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:182)\n\tat org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:231)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: org.apache.kafka.common.errors.RecordTooLargeException: The message is 1996106 bytes when serialized which is larger than 1048576, which is the value of the max.request.size configuration.\n",
            "worker_id": "xxx.xxx.xx.xxx:8083"
        }
    ],
    "type": "source"
}
```

这是因为 debezium 抽到的数据大小超过了它能发送的大小限制，这个限制默认为 1M。



### 修复方案

参考：[Running Kafka Connect](https://kafka.apache.org/documentation/#connect_running)

> Starting with 2.3.0, client configuration overrides can be configured individually per connector by using the prefixes `producer.override.` and `consumer.override.` for Kafka sources or Kafka sinks respectively. These overrides are included with the rest of the connector's configuration properties.

可以直接发送 POST 请求更新 connector 配置即可：

```shell
$ cat MY_CONNECTOR.json
{
    ...
    # 新增配置项
    "producer.override.max.request.size": 10485880
}

$ curl -X PUT -v http://xxx.xxx.xx.xxx:8083/connectors/MY_CONNECTOR/config -d @MY_CONNECTOR.json --header 'Content-Type: application/json'
```

需要注意的是，如果在启动 kafka connect 时有配置 `connector.client.config.override.policy` 参数允许覆盖 `producer` 的一些配置，那么这种方式才会生效，否则大概率会遇到下面的错误：

```shell
{"error_code":400,"message":"Connector configuration is invalid and contains the following 1 error(s):\nThe 'None' policy does not allow 'max.request.size' to be overridden in the connector configuration.\nYou can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`"}
```



关于  `connector.client.config.override.policy` 的参数可以参考文档 [`connector.client.config.override.policy`](https://kafka.apache.org/documentation/#connectconfigs_connector.client.config.override.policy)

>Class name or alias of implementation of `ConnectorClientConfigOverridePolicy`. Defines what client configurations can be overridden by the connector. The default implementation is `All`, meaning connector configurations can override all client properties. The other possible policies in the framework include `None` to disallow connectors from overriding client properties, and `Principal` to allow connectors to override only client principals.

如果恰巧遇到这种情况的话就需要修改 kafka connect 的配置文件了（`config/connect-distributed.properties`），在文件里面新增：

```shell
# 最大可发送 10M
producer.max.request.size=10485880
```



除此之外，还修改 kafka topic 配置，因为 kafka 默认也只支持接收 1M 内的消息，要改为支持接收 10M 以内的数据，可以使用下面的命令：

```shell
bin/kafka-configs.sh --bootstrap-server xxx.xxx.xx.xxx:9092 --alter --entity-type topics --entity-name EX3D75_FORWARD --add-config max.message.bytes=10485880
```



这个操作是为了避免重启 kafka，也可以调整 kafka server.properties 文件对所有 topic 生效。这种方式需要重启 kafka，调整 kafka 的配置文件，增加下面的配置项：

```shell
# server.properties
message.max.bytes=10485880
```



最后别忘了重启 kafka connect。



### Reference

1. [How to send Large Messages in Apache Kafka?](https://www.conduktor.io/kafkahow-to-send-large-messages-in-apache-kafka/)